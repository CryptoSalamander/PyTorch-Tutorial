{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab12 XOR Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "100 0.6931471824645996\n",
      "200 0.6931471824645996\n",
      "300 0.6931471824645996\n",
      "400 0.6931471824645996\n",
      "500 0.6931471824645996\n",
      "600 0.6931471228599548\n",
      "700 0.6931452751159668\n",
      "800 0.6930633187294006\n",
      "900 0.6412245035171509\n",
      "1000 0.2531474232673645\n",
      "1100 0.03129035234451294\n",
      "1200 0.016702039167284966\n",
      "1300 0.01122652180492878\n",
      "1400 0.008407686837017536\n",
      "1500 0.006701599806547165\n",
      "1600 0.0055622230283916\n",
      "1700 0.004749101586639881\n",
      "1800 0.0041405013762414455\n",
      "1900 0.0036683687940239906\n",
      "2000 0.003291659988462925\n",
      "2100 0.0029842909425497055\n",
      "2200 0.0027288016863167286\n",
      "2300 0.0025131446309387684\n",
      "2400 0.002328727161511779\n",
      "2500 0.0021692693699151278\n",
      "2600 0.002030052011832595\n",
      "2700 0.001907495898194611\n",
      "2800 0.0017987260362133384\n",
      "2900 0.0017015874618664384\n",
      "3000 0.0016142991371452808\n",
      "3100 0.0015355143696069717\n",
      "3200 0.001463932334445417\n",
      "3300 0.0013986851554363966\n",
      "3400 0.0013389657251536846\n",
      "3500 0.0012841307325288653\n",
      "3600 0.001233537564985454\n",
      "3700 0.0011867679422721267\n",
      "3800 0.0011433582985773683\n",
      "3900 0.001103009795770049\n",
      "4000 0.0010654086945578456\n",
      "4100 0.0010302263544872403\n",
      "4200 0.0009973281994462013\n",
      "4300 0.0009663707460276783\n",
      "4400 0.0009373538196086884\n",
      "4500 0.0009099790477193892\n",
      "4600 0.0008841564413160086\n",
      "4700 0.0008597518899478018\n",
      "4800 0.0008366158581338823\n",
      "4900 0.0008147335611283779\n",
      "5000 0.0007939257193356752\n",
      "5100 0.0007741623558104038\n",
      "5200 0.0007553243776783347\n",
      "5300 0.0007374264532700181\n",
      "5400 0.0007203490822575986\n",
      "5500 0.0007039880147203803\n",
      "5600 0.0006883729947730899\n",
      "5700 0.0006734293419867754\n",
      "5800 0.0006591273122467101\n",
      "5900 0.0006454369286075234\n",
      "6000 0.0006322836852632463\n",
      "6100 0.0006196376052685082\n",
      "6200 0.0006074839038774371\n",
      "6300 0.0005957777029834688\n",
      "6400 0.0005845638224855065\n",
      "6500 0.000573722820263356\n",
      "6600 0.0005632846150547266\n",
      "6700 0.0005532341892831028\n",
      "6800 0.0005435418570414186\n",
      "6900 0.0005341328796930611\n",
      "7000 0.0005250669782981277\n",
      "7100 0.0005163142923265696\n",
      "7200 0.0005078301182948053\n",
      "7300 0.0004996442003175616\n",
      "7400 0.0004916671314276755\n",
      "7500 0.00048395851626992226\n",
      "7600 0.0004765183839481324\n",
      "7700 0.000469301943667233\n",
      "7800 0.0004622793640010059\n",
      "7900 0.00045543580199591815\n",
      "8000 0.00044881596113555133\n",
      "8100 0.00044238995178602636\n",
      "8200 0.00043617276242002845\n",
      "8300 0.00043008977081626654\n",
      "8400 0.0004242006689310074\n",
      "8500 0.00041841596248559654\n",
      "8600 0.00041285494808107615\n",
      "8700 0.0004073833697475493\n",
      "8800 0.00040207590791396797\n",
      "8900 0.0003969025856349617\n",
      "9000 0.00039187842048704624\n",
      "9100 0.00038694372051395476\n",
      "9200 0.0003821431891992688\n",
      "9300 0.0003774769138544798\n",
      "9400 0.0003729150048457086\n",
      "9500 0.00036847242154181004\n",
      "9600 0.00036408944288268685\n",
      "9700 0.0003598704934120178\n",
      "9800 0.00035569630563259125\n",
      "9900 0.00035164138535037637\n",
      "10000 0.0003476759302429855\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0,0], [0,1], [1,0], [1,1]]).to(device)\n",
    "Y= torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "# nn Layers\n",
    "w1 = torch.Tensor(2,2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2,1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)\n",
    "\n",
    "def sigmoid(x):\n",
    "    # sigmoid function\n",
    "    return 1.0 / (1.0 + torch.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "for step in range(10001):\n",
    "    # forward\n",
    "    l1 = torch.add(torch.matmul(X,w1), b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1, w2), b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1 - Y) * torch.log(1 - Y_pred)) # Binary Cross Entropy\n",
    "    \n",
    "    # Back Prop (chain rule)\n",
    "    # Loss Derivative\n",
    "    d_Y_pred = (Y_pred - Y) / (Y_pred * (1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    # Layer 2\n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_b2)\n",
    "    \n",
    "    # Layer 1\n",
    "    d_a1 = torch.matmul(d_b2, torch.transpose(w2,0,1))\n",
    "    d_l1 = d_a1 * sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X,0,1), d_b1)\n",
    "    \n",
    "    # Weight Update\n",
    "    learning_rate = 1\n",
    "    w1 = w1 - learning_rate * d_w1\n",
    "    b1 = b1 - learning_rate * torch.mean(d_b1,0)\n",
    "    w2 = w2 - learning_rate * d_w2\n",
    "    b2 = b2 - learning_rate * torch.mean(d_b2,0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5002],\n",
      "        [0.7310],\n",
      "        [0.7310],\n",
      "        [0.5001]])\n"
     ]
    }
   ],
   "source": [
    "print(sigmoid(Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0,1,1,0에 가까워짐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
